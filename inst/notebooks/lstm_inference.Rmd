---
title: "lstm_inference"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{lstm_inference}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Set parameters

```{r }
model_path <- "/DEVEL/code/rpackages/mitre/inst/notebooks/models/0.0479_follows/"
codename <- "follows"
col2predict <- "version"
seed <- 42
# num_samples <- 25000  # Number of samples to train on.
# test_size <- 0.05 # Slice percentage from num_samples
# validation_size <- 0.2 # percentage of train set used for validation
# batch_size <- 64  # Batch size for training.
# epochs <- 500  # Number of epochs to train for.
# latent_dim <- 256  # Latent dimensionality of the encoding space.

# modelconf <- list(col2predict, seed, num_samples, test_size, validation_size, batch_size, epochs, latent_dim)
# saveRDS(modelconf, paste0("modelconf.", codename, ".rds"))

set.seed(seed)
```

REF: https://github.com/rstudio/keras/blob/master/vignettes/examples/lstm_seq2seq.R

## Sequence to sequence example in Keras (character-level).

This script demonstrates how to implement a basic character-level sequence-to-sequence model. We apply it to translating short English sentences into short French sentences, character-by-character. Note that it is fairly unusual to do character-level machine translation, as word-level models are more common in this domain.

## Algorithm

- We start with input sequences from a domain (e.g. English sentences) and correspding target sequences from another domain (e.g. French sentences).
- An encoder LSTM turns input sequences to 2 state vectors (we keep the last LSTM state and discard the outputs).
- A decoder LSTM is trained to turn the target sequences into the same sequence but offset by one timestep in the future, a training process called “teacher forcing” in this context. Is uses as initial state the state vectors from the encoder. Effectively, the decoder learns to generate targets[t+1...] given targets[...t], conditioned on the input sequence.
- In inference mode, when we want to decode unknown input sequences, we:
  - Encode the input sequence into state vectors
  - Start with a target sequence of size 1 (just the start-of-sequence character)
  - Feed the state vectors and 1-char target sequence to the decoder to produce predictions for the next character
  - Sample the next character using these predictions (we simply use argmax).
  - Append the sampled character to the target sequence
  - Repeat until we generate the end-of-sequence character or we hit the character limit.

```{r setup}
library(mitre)
library(keras)
suppressPackageStartupMessages(library(data.table))
suppressPackageStartupMessages(library(dplyr))

```


```{r get_inventory, cache=TRUE}
df_inventory <- mitre::getInventory()
```

```{r get_inventory, cache=TRUE}
# kk <- df_inventory %>%
#   bind_cols(
#     bind_rows(apply(df_inventory, 1,
#                     function(x) as.data.frame(stringdist::afind(x[1], x[2]))))) %>%
#   mutate(verlen = 1 - (distance/nchar(version)))
# df_inventory <- dplyr::bind_cols(df_inventory,
#                                  dplyr::bind_rows(apply(df_inventory, 1, 
#                                                         function(x) 
#                                                           as.data.frame(stringdist::afind(x[1], x[2])))))
```

```{r prepare_inventory, cache=TRUE}
# Adapt SCCM inventory to CPE data frame
df_inventory$deprecated <- FALSE
df_inventory$title <- stringr::str_trim(paste(df_inventory$vendor, df_inventory$name))
names(df_inventory)[names(df_inventory) == "name"] <- "product"
df_inventory$id <- 1:nrow(df_inventory)
df_inventory <- df_inventory[, c("id", "title", "vendor", "product", "version", "deprecated")]
# lowercase title
df_inventory$title <- tolower(df_inventory$title)

df_input <- mitre::nlp_cpe_dataset(df_inventory)
```

## Load the model

```{r }
model <- load_model_hdf5(filepath = paste0(model_path, 'lstm_', codename, "_", col2predict, '_span.h5'))
load_model_weights_hdf5(object = model, filepath = paste0(model_path, 'lstm_', codename, "_", col2predict, '_span-wt.h5'))


model_infer_decoder <- load_model_hdf5(filepath = paste0(model_path, 
                                                         'lstm_', codename, "_", col2predict, 
                                                         '_inference_decoder_model.h5'))
load_model_weights_hdf5(object = model_infer_decoder, 
                        filepath = paste0(model_path, 'lstm_', codename, "_", col2predict, 
                                          '_inference_decoder_model-wt.h5'))

model_infer_encoder <- load_model_hdf5(filepath = paste0(model_path, 
                                                         'lstm_', codename, "_", col2predict, 
                                                         '_inference_encoder.h5'))
load_model_weights_hdf5(object = model_infer_encoder, 
                        filepath = paste0(model_path, 'lstm_', codename, "_", col2predict, 
                                          '_inference_encoder-wt.h5'))

```

## Next: inference mode (sampling).

Here's the drill:
 1) encode input and retrieve initial decoder state
 2) run one step of decoder with this initial state and a "start of sequence" token as target.  Output will be the next target token
 3) Repeat with the current target token and current states

```{r }
# input_texts  <- stringr::str_trim(paste(df_inventory$vendor, df_inventory$name, df_inventory$version))
# input_texts  <- lapply( input_texts, function(s) strsplit(s, split = "")[[1]])

input_texts  <- lapply(stringr::str_trim(tolower(df_inventory$title)), 
                       function(s) strsplit(s, split = "")[[1]])
```

## Define encoder/decoder tokens

```{r }
input_characters  <- sort(unique(enc_valid_chars()))
target_characters <- sort(unique(tolower(enc_valid_chars(add_tab = T, add_enter = T))))
num_encoder_tokens <- length(input_characters)
num_decoder_tokens <- length(target_characters)
max_encoder_seq_length <- max(sapply(input_texts,length))
# max_decoder_seq_length <- max(sapply(target_texts,length))
max_decoder_seq_length <- 80

cat('Number of samples:', length(input_texts),'\n')
cat('Number of unique input tokens:', num_encoder_tokens,'\n')
cat('Number of unique output tokens:', num_decoder_tokens,'\n')
cat('Max sequence length for inputs:', max_encoder_seq_length,'\n')
cat('Max sequence length for outputs:', max_decoder_seq_length,'\n')
```


```{r }
## Reverse-lookup token index to decode sequences back to
## something readable.
reverse_input_char_index  <- as.character(input_characters)
reverse_target_char_index <- as.character(target_characters)

```


```{r }
input_token_index  <- 1:length(input_characters)
names(input_token_index) <- input_characters
target_token_index <- 1:length(target_characters)
names(target_token_index) <- target_characters
encoder_input_data <- array(
  0, dim = c(length(input_texts), max_encoder_seq_length, num_encoder_tokens))
decoder_input_data <- array(
  0, dim = c(length(input_texts), max_decoder_seq_length, num_decoder_tokens))
decoder_target_data <- array(
  0, dim = c(length(input_texts), max_decoder_seq_length, num_decoder_tokens))

for(i in 1:length(input_texts)) {
  d1 <- sapply( input_characters, function(x) { as.integer(x == input_texts[[i]]) })
  encoder_input_data[i,1:nrow(d1),] <- d1
  # d2 <- sapply( target_characters, function(x) { as.integer(x == target_texts[[i]]) })
  # decoder_input_data[i,1:nrow(d2),] <- d2
  # d3 <- sapply( target_characters, function(x) { as.integer(x == target_texts[[i]][-1]) })
  # decoder_target_data[i,1:nrow(d3),] <- d3
}
```


```{r }
decode_sequence <- function(input_seq) {
  ## Encode the input as state vectors.
  states_value <- predict(model_infer_encoder, input_seq)
  
  ## Generate empty target sequence of length 1.
  target_seq <- array(0, dim = c(1, 1, num_decoder_tokens))
  ## Populate the first character of target sequence with the start character.
  target_seq[1, 1, target_token_index['\t']] <- 1.
  
  ## Sampling loop for a batch of sequences
  ## (to simplify, here we assume a batch of size 1).
  stop_condition = FALSE
  decoded_sentence = ''
  maxiter = max_decoder_seq_length
  niter = 1
  while (!stop_condition && niter < maxiter) {
    
    ## output_tokens, h, c = decoder_model.predict([target_seq] + states_value)
    decoder_predict <- predict(model_infer_decoder, c(list(target_seq), states_value))
    output_tokens <- decoder_predict[[1]]
    
    ## Sample a token
    sampled_token_index <- which.max(output_tokens[1, 1, ])
    sampled_char <- reverse_target_char_index[sampled_token_index]
    decoded_sentence <-  paste0(decoded_sentence, sampled_char)
    decoded_sentence
    
    ## Exit condition: either hit max length
    ## or find stop character.
    if (sampled_char == '\n' ||
        length(decoded_sentence) > max_decoder_seq_length) {
      stop_condition = TRUE
    }
    
    ## Update the target sequence (of length 1).
    ## target_seq = np.zeros((1, 1, num_decoder_tokens))
    target_seq[1, 1, ] <- 0
    target_seq[1, 1, sampled_token_index] <- 1.
    
    ## Update states
    h <- decoder_predict[[2]]
    c <- decoder_predict[[3]]
    states_value = list(h, c)
    niter <- niter + 1
  }    
  return(decoded_sentence)
}

```


# INFERENCE

```{r }
results <- data.frame(input = character(), 
                      output = character())

for (seq_index in 1:length(input_texts)) {
  input_sentence  <- paste(input_texts[[seq_index]], collapse = '')
  input_seq = encoder_input_data[seq_index,,,drop = FALSE]
  output_sentence = decode_sequence(input_seq)
  
  results <- rbind(results, 
                   data.frame(input = input_sentence, 
                              output = output_sentence))
  
  cat('-\n')
  cat('Input sentence  : ', input_sentence,'\n')
  cat('Output sentence : ', output_sentence,'\n')
}

results$output <- stringr::str_trim(results$output)
results$input <- stringr::str_trim(results$input)

kk <- results %>%
  bind_cols(
    bind_rows(apply(results, 1,
                    function(x) as.data.frame(stringdist::afind(x[1], x[2]))))) %>%
  mutate(verlen = 1 - (distance/nchar(output)))

saveRDS(results, "latest_results.rds")
```




